{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# Document Search with Universal Sentence Encoder\n",
    "\n",
    "Originally by [Jeremy B. Merrill](https://twitter.com/jeremybmerrill), formerly of Quartz, for NICAR 2020. Updated lightly throughout by John Keefe.\n",
    "\n",
    "Original Github repos:\n",
    "\n",
    "- https://github.com/Quartz/aistudio-searching-data-dumps-with-use\n",
    "- https://github.com/Quartz/aistudio-workshops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOTzp8O36CyQ"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "This notebook was originally set up to run on Google's [Colaboratory](https://colab.research.google.com/) service. To try it yourself:\n",
    "\n",
    "- Go to [colab.research.google.com](https://colab.research.google.com/)\n",
    "- Choose the \"Github\" tab\n",
    "- Type \"jkeefe\" on the top line and press enter.\n",
    "- Pick the \"black-lives-matter-words\" repo\n",
    "- Pick this notebook, `semantic_scoring.ipynb`\n",
    "\n",
    "**IMPORTANT** Note: Once the notebook is running go to ***Runtime->Change Runtime type*** dropdown menu above and pick **GPU** _before_ running this notebook for faster execution.\n",
    "\n",
    "This is an interactive demo. You can run all the code necessary right here.\n",
    "\n",
    "We're using two neat pieces of technology called the *Universal Sentence Encoder* and *Annoy*.\n",
    "\n",
    "- the *Universal Sentence Encoder* is a pre-trained machine-learning model that sorta understands human language. If you feed in a sentence, it comes out with 512 numbers that represent the approximate meaning of that sentence. What's really cool is that if you feed in a second sentence that means about the same thing, that second sentence's numbers will be very close to those of the first sentence.\n",
    "- *Annoy* is a library that makes it really easy to find points in vector space that are close to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrZqHVFBGfW"
   },
   "source": [
    "What's \"vector space\"? Imagine dot plot with an x-axis and a y-axis. That's two-dimensional vector space.\n",
    "\n",
    "This is three-dimensional vector space. Three axes: x, y, z.\n",
    "\n",
    "![alt text](https://filedn.com/lVaAxkskVxILBoUDG3XUrm7/nicar20presentation/Screen%20Shot%202020-02-28%20at%205.43.59%20PM.png)\n",
    "\n",
    "Now imagine 512 axes. That's what we're dealing with here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZPVY12mDb0P"
   },
   "source": [
    "## Okay, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to install everything you need. It'll take a few minutes. Note that we're actually downgrading to an old version of TensorFlow here. (The new version would work, I'm sure, but I haven't refactored it yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "lVjNK8shFKOC",
    "outputId": "e2860042-99ed-4c1a-fd14-33d63b63e929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 377.0MB 41kB/s \n",
      "\u001b[K     |████████████████████████████████| 3.2MB 58.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 491kB 53.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 109.2MB 28kB/s \n",
      "\u001b[K     |████████████████████████████████| 2.1MB 4.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 645kB 4.6MB/s \n",
      "\u001b[?25h  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#@title Setup Environment\n",
    "#latest Tensorflow that supports sentencepiece is 1.14\n",
    "!pip uninstall --quiet --yes tensorflow\n",
    "!pip install --quiet tensorflow-gpu==1.14\n",
    "!pip install --quiet tensorflow==1.14\n",
    "!pip install --quiet tensorflow-hub\n",
    "!pip install --quiet bokeh\n",
    "!pip install --quiet tf-sentencepiece\n",
    "!pip install --quiet annoy\n",
    "!pip install --quiet tqdm\n",
    "!pip install --quiet w3lib\n",
    "!pip install --quiet syntok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load in everything we just installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha",
    "outputId": "e6af0ffb-43ac-484c-c978-f8913acc8c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "#@title Setup common imports and functions\n",
    "%tensorflow_version 1.x\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tf_sentencepiece  # Not used directly but needed to import TF ops.\n",
    "import sklearn.metrics.pairwise\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gk2IRjZFGDsK"
   },
   "source": [
    "This is additional boilerplate code where we import the pre-trained ML model we will use to encode text throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mkmF3w8WGLcM",
    "outputId": "c5e6c192-fd64-4227-a5f7-ce2693c43dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "#@title get the machine learning stuff set up. (boilerplate!)\n",
    "# this version of the Universal Sentence Encoder only \"speaks\" English\n",
    "# but there's another version you can switch in that supports 16 different languages!\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder/2'\n",
    "\n",
    "# boilerplate, getting started with Tensorflow.\n",
    "# (how to use Tensorflow is way outside the scope of this class)\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  multiling_embed = hub.Module(module_url)\n",
    "  embedded_text = multiling_embed(text_input)\n",
    "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "session = tf.Session(graph=g)\n",
    "session.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eExMTHZNGn86"
   },
   "source": [
    "## What the heck is JSONL?\n",
    "\n",
    "Don't worry too much about it. It looks like this, but there's nothing special to it, it's just a way to get the content of the statments. Here's one line:\n",
    "\n",
    "```json\n",
    "{\"_source\": {\"content\": \"For all of us who care deeply about diversity, equality and fairness, it\\u2019s been painful and heartbreaking to watch the tragic events of this past week in Minneapolis and in several other parts of America. These events are emblematic of the inequities that black and other diverse communities face on a daily basis. The need for change is evident and we know that more work needs to be done to ensure that all people in all communities feel included, equal and safe. As a company that is deeply committed to diversity, inclusion and human rights, we will strengthen our resolve in advocating for change and in doing our part so that we build a society that protects all people and values all voices.\"},  \"_id\": \"MetLife.txt\"}\n",
    "```\n",
    "\n",
    "I used another notebook in this repo `jsonl_maker.ipynb` to turn the collection of statements, each in its own text file, into a single JSONL file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XjNsxF2b7ZU"
   },
   "outputs": [],
   "source": [
    "# @ get the data.\n",
    "# let's get our data!\n",
    "# it's a JSONL file, which has each statement as its own JSON document, and each JSON document on one line.\n",
    "!wget --quiet -nc -O docs.jsonl https://www.dropbox.com/s/watyjmstbsorsh4/docs.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVmKpe5hnsxx"
   },
   "source": [
    "## Chopping each page into a list of sentences\n",
    "\n",
    "We have to do this because pages and paragraphs often cover multiple topics, which might confuse the model. And, Universal Sentence Encoder is built to encode sentences... and so it ignores anything after the 128th word in its input.\n",
    "\n",
    "The code below cuts the text into sentences, but groups any two consecutive sentences under 10 words long together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5nTA-aV4pH-k",
    "outputId": "7b773a98-cffb-41dd-b64e-ce7849ec668b"
   },
   "outputs": [],
   "source": [
    "# how many lines our in our document?\n",
    "!wc docs.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LEh77ZORnrrr",
    "outputId": "e707ee40-aea8-4bb7-843e-68c5edc2e169"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 160.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total paragraphs: 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce\n",
    "from w3lib.html import remove_tags\n",
    "\n",
    "import syntok.segmenter as segmenter\n",
    "\n",
    "total_docs = 88 # get this with `wc` (only used for progress bar)\n",
    "\n",
    "total_short_paragraphs = 0\n",
    "MAX_SENT_LEN = 50\n",
    "\n",
    "def sentenceify(text):\n",
    "    return [sl for l in [[''.join([t.spacing + t.value for t in s]) for s in p if len(s) < MAX_SENT_LEN] for p in segmenter.analyze(text)] for sl in l if any(map(lambda x: x.isalpha(), sl))]\n",
    "\n",
    "\n",
    "def clean_html(html):\n",
    "    if \"<\" in html and \">\" in html:\n",
    "        try:\n",
    "            soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "            plist = soup.find('plist')\n",
    "            if plist:\n",
    "                plist.decompose() # remove plists because ugh\n",
    "            text = soup.getText()\n",
    "        except:\n",
    "            text = remove_tags(html)\n",
    "        return '. '.join(text.split(\"\\r\\n\\r\\n\\r\\n\"))\n",
    "    else:\n",
    "        return '. '.join(html.split(\"\\r\\n\\r\\n\\r\\n\"))\n",
    "\n",
    "# if this sentence is short, then group it with other short sentences (so you get groups of continuous short sentences, broken up by one-element groups of longer sentences)\n",
    "def short_sentence_grouper_bean_factory(target_sentence_length): # in chars\n",
    "    def group_short_sentences(list_of_lists_of_sentences, next_sentence):\n",
    "        if not list_of_lists_of_sentences:\n",
    "            return [[next_sentence]]\n",
    "        if len(next_sentence) < target_sentence_length:\n",
    "           list_of_lists_of_sentences[-1].append(next_sentence)\n",
    "        else:\n",
    "            list_of_lists_of_sentences.append([next_sentence])\n",
    "            list_of_lists_of_sentences.append([])\n",
    "        return list_of_lists_of_sentences\n",
    "    return group_short_sentences\n",
    "\n",
    "\n",
    "def overlap(document_tokens, target_length):\n",
    "    \"\"\" pseudo-paginate a document by creating lists of tokens of length `target-length` that overlap at 50%\n",
    "    return a list of `target_length`-length lists of tokens, overlapping by 50% representing all the tokens in the document \n",
    "    \"\"\"\n",
    "\n",
    "    overlapped = []\n",
    "    cursor = 0\n",
    "    while len(' '.join(document_tokens[cursor:]).split()) >= target_length:\n",
    "      overlapped.append(document_tokens[cursor:cursor+target_length])\n",
    "      cursor += target_length // 2\n",
    "    return overlapped\n",
    "\n",
    "\n",
    "def sentences_to_short_paragraphs(group_of_sentences, target_length, min_shingle_length=10):\n",
    "    \"\"\" outputting overlapping groups of shorter sentences \n",
    "    \n",
    "        group_of_sentences = list of strings, where each string is a sentences\n",
    "        target_length = max length IN WORDS of output sentennces\n",
    "        min_shingle_length = don't have sentences that differ just in the inclusion of a sentence of this size\n",
    "    \"\"\"\n",
    "    if len(group_of_sentences) == 1:\n",
    "        return [' '.join(group_of_sentences[0].split())]\n",
    "    sentences_as_words = [sent.split() for sent in group_of_sentences]\n",
    "    sentences_as_words = [sentence for sentence in sentences_as_words if [len(word) for word in sentence].count(1) < (len(sentence) * 0.5) ]\n",
    "    paragraphs = []\n",
    "    for i, sentence in enumerate(sentences_as_words[:-1]):\n",
    "        if i > 0 and len(sentence) < min_shingle_length  and len(sentences_as_words[i-1]) < min_shingle_length and i % 2 == 0:\n",
    "            continue # skip really short sentences if the previous one is also really short (but not so often that we lose anything )\n",
    "        buff = list(sentence) # just making a copy.\n",
    "        for subsequent_sentence in sentences_as_words[i+1:]:\n",
    "            if len(buff) + len(subsequent_sentence) <= target_length:\n",
    "                buff += subsequent_sentence\n",
    "            else:\n",
    "                break\n",
    "        paragraphs.append(buff)\n",
    "    return [' '.join(graf) for graf in paragraphs]\n",
    "\n",
    "\n",
    "def to_short_paragraphs(text, paragraph_len=15, min_sentence_len=8): # paragraph_len in words, min_sentence_len in chars\n",
    "    sentences = sentenceify( clean_html(text) )\n",
    "    grouped_sentences = reduce(short_sentence_grouper_bean_factory(150) , sentences, [])\n",
    "    return [sl for l in [sentences_to_short_paragraphs(group, paragraph_len) for group in grouped_sentences if len(group) >= 2 or (len(group) > 0 and len(group[0]) > min_sentence_len)] for sl in l if sl]\n",
    "\n",
    "paragraph_target_length = 10\n",
    "\n",
    "with open(f\"docs-sentences{paragraph_target_length}.json\", 'w') as writer: \n",
    "    with open('docs.jsonl', 'r') as reader:\n",
    "        for i, line_json in tqdm(enumerate(reader), total=total_docs):\n",
    "            line = json.loads(line_json)\n",
    "            text = line[\"_source\"][\"content\"][:1000000]\n",
    "            for j, page in enumerate(to_short_paragraphs(text, paragraph_target_length)):\n",
    "                total_short_paragraphs += 1\n",
    "                writer.write(json.dumps({\n",
    "                    \"text\": page, \n",
    "                    \"_id\": line[\"_id\"], \n",
    "                    \"chonk\": j,\n",
    "                    # \"routing\": line.get(\"_routing\", None),\n",
    "                    # \"path\": line[\"_source\"][\"path\"]\n",
    "                    }) + \"\\n\")\n",
    "print(f\"total paragraphs: {total_short_paragraphs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few lines of the sentences file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "MqvfzGZVueGP",
    "outputId": "e27e98ae-33b3-4432-f302-3fa0747865e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"I wanted to say something earlier but was afraid it would come out wrong or that I wouldn't be able to find the words to express how I really feel.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 0}\n",
      "{\"text\": \"However, I\\u2019ve realized that staying silent is far worse because, like you;\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 1}\n",
      "{\"text\": \"The murders of George Floyd in Minneapolis, Breonna Taylor in Kentucky, and Ahmaud Arbery in Georgia are the most recent names added to a lengthy list of horrors faced by black people over the past several hundred years.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 2}\n",
      "{\"text\": \"During this troublesome time, even when most people are craving normalcy, we must not turn a blind eye to injustices and continue to stand on the sidelines.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 3}\n",
      "{\"text\": \"Returning to the status quo will only perpetuate the damage being done.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 4}\n",
      "{\"text\": \"Everyone must do more to support the Black community.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 5}\n",
      "{\"text\": \"Taking the time to educate yourself and understand someone else\\u2019s perspective is one of the simplest, yet most powerful ways to show your support.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 6}\n",
      "{\"text\": \"I'll admit until recently I didn't understand what the Black Lives Matter movement was actually about.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 7}\n",
      "{\"text\": \"Why were the \\u201cAll Lives Matter\\u201d social media posts looked at as racist?\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 8}\n",
      "{\"text\": \"I had to be missing something.\", \"_id\": \"Berkshire Hathaway.txt\", \"chonk\": 9}\n"
     ]
    }
   ],
   "source": [
    "!head docs-sentences10.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxAFAJI9xsAU"
   },
   "source": [
    "# Creating a Multilingual Semantic-Similarity Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3DIT9uT7Z34"
   },
   "source": [
    "## Using a pre-trained model to transform sentences into vectors\n",
    "\n",
    "We compute embeddings in _batches_ so that they fit in the GPU's RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yRoRT5qCEIYy",
    "outputId": "46c642d3-8089-4ba7-f33d-9629883bbd08"
   },
   "outputs": [],
   "source": [
    "vector_index_chunk = AnnoyIndex(512, 'angular')  # Length of item vector that will be indexed\n",
    "\n",
    "batch_size = 256\n",
    "docs = {}\n",
    "\n",
    "doc_counter = 0\n",
    "with tqdm(total=1680) as pbar:\n",
    "  for j, batch in enumerate(pd.read_json('docs-sentences10.json', lines=True, chunksize=batch_size)):\n",
    "    batch_vecs = session.run(embedded_text, feed_dict={text_input: batch[\"text\"]})\n",
    "    # sentences.extend(batch[\"text\"])\n",
    "    pbar.update(len(batch))\n",
    "    doc_idxs = list(range(doc_counter, doc_counter + batch_size))\n",
    "    for vec, page_num, doc in zip(batch_vecs, doc_idxs, batch.iterrows()):\n",
    "      vector_index_chunk.add_item(page_num, vec)\n",
    "      docs[page_num] = doc[1][\"_id\"]\n",
    "    doc_counter += batch_size\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeBqoE8e-scg"
   },
   "source": [
    "## Building an index of semantic vectors\n",
    "\n",
    "We use the [Annoy](https://github.com/spotify/annoy) library---to efficiently look up results from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SmoB9I9Pe4IT",
    "outputId": "652e991b-14a7-400b-95c8-49c39cb59260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_index_chunk.build(10) # 10 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WHcd4w22p3g-",
    "outputId": "423c842d-dc48-4cbf-fa8c-40f43ef7a761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_index_chunk.save('docs_annoy_small.bin') # you could save this and skip the step above, if you'd like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRVX_CFopDyy"
   },
   "source": [
    "What's indexed in Annoy is a meaningless set of 512 numbers for each sentence. Computers can sort of understand this, but humans can't. So we load up into memory the list of all the sentences, so we can print those as the result.\n",
    "\n",
    "This demo uses a fairly small (5mb) set of documents. If you were using this in \"real life\" you'd probably want to use a database to hold onto these -- they'd be too big to hold in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxzNAzI6mwtH"
   },
   "outputs": [],
   "source": [
    "doc_texts = pd.read_json('docs-sentences10.json', lines=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kg9cw0S2_ntQ"
   },
   "source": [
    "## Verify that the semantic-similarity search engine works\n",
    "\n",
    "Here are all the sentences in our collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "u6S0zd96xkY2",
    "outputId": "cfde6def-3183-47d2-e7cd-b1c32ce11cc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>_id</th>\n",
       "      <th>chonk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wanted to say something earlier but was afra...</td>\n",
       "      <td>Berkshire Hathaway.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, I’ve realized that staying silent is ...</td>\n",
       "      <td>Berkshire Hathaway.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The murders of George Floyd in Minneapolis, Br...</td>\n",
       "      <td>Berkshire Hathaway.txt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>During this troublesome time, even when most p...</td>\n",
       "      <td>Berkshire Hathaway.txt</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Returning to the status quo will only perpetua...</td>\n",
       "      <td>Berkshire Hathaway.txt</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>It’s also why today Intel is pledging $1 milli...</td>\n",
       "      <td>Intel.txt</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>I also encourage employees to consider donatin...</td>\n",
       "      <td>Intel.txt</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>It’s with a heavy heart that I write this note...</td>\n",
       "      <td>Intel.txt</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>I know I speak for the leadership team, our bo...</td>\n",
       "      <td>Intel.txt</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>Together we will get through this.</td>\n",
       "      <td>Intel.txt</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ... chonk\n",
       "0     I wanted to say something earlier but was afra...  ...     0\n",
       "1     However, I’ve realized that staying silent is ...  ...     1\n",
       "2     The murders of George Floyd in Minneapolis, Br...  ...     2\n",
       "3     During this troublesome time, even when most p...  ...     3\n",
       "4     Returning to the status quo will only perpetua...  ...     4\n",
       "...                                                 ...  ...   ...\n",
       "1675  It’s also why today Intel is pledging $1 milli...  ...    29\n",
       "1676  I also encourage employees to consider donatin...  ...    30\n",
       "1677  It’s with a heavy heart that I write this note...  ...    31\n",
       "1678  I know I speak for the leadership team, our bo...  ...    32\n",
       "1679                 Together we will get through this.  ...    33\n",
       "\n",
       "[1680 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try searching for similar sentences yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dxu66S8wJIG9"
   },
   "source": [
    "*   Try a few different sample sentences\n",
    "*   Try changing the number of returned results (they are returned in order of similarity)\n",
    "\n",
    "Once you've tried it out a bit, click the menu button to the left, and click Form -> Show Code to see what this is doing under the hood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"These events impact us, our customers and the communities we serve, and we are called to action. \"  #@param [\"We cannot tolerate it and none of us can stand by quietly if we observe it.\"] {allow-input: true}\n",
    "num_results = 15  #@param {type:\"slider\", min:0, max:50, step:1}\n",
    "\n",
    "query_embedding = session.run(embedded_text, feed_dict={text_input: [sample_query]})[0]\n",
    "\n",
    "search_results = vector_index_chunk.get_nns_by_vector(query_embedding, n=num_results)\n",
    "\n",
    "print('sentences similar to: \"{}\"\\n'.format(sample_query))\n",
    "# search_results\n",
    "\n",
    "for idx, result_idx in enumerate(search_results):\n",
    "  page_num = docs[result_idx]\n",
    "  text = doc_texts.iloc[result_idx][\"text\"]\n",
    "  print(f\"{idx + 1}, \\\"{text}\\\", {page_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how I ran the sentences Sonia gave me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eDvx3SWXSVY"
   },
   "outputs": [],
   "source": [
    "query_sentences = [\"it's more important than ever that we ground ourselves in the fundamental values that define us as a company.\",\n",
    "\"Recent racial discrimination incidents in Minnesota, New York, Kentucky and Georgia have drawn widespread national attention\",\n",
    "\"our focus on our values of respect, diversity and inclusion cannot waver. \",\n",
    "\"Supporting, encouraging and engaging everyone in our company – no matter their gender, color of their skin, sexual orientation, disability, religion, point of view or other unique qualities – are actions we must take every day. \",\n",
    "\"While social distancing separates us, this is not a time to be passive, but a time to reach out to colleagues, engage in a dialogue, make sure they're okay and their voices are heard. To let them know they are valued and important.\",\n",
    "\"There is no room in our company for hate, intolerance, discrimination or harassment of any kind – either obvious or covert – toward our colleagues or customers. \",\n",
    "\"We cannot tolerate it and none of us can stand by quietly if we observe it.\",\n",
    "\"These events impact us, our customers and the communities we serve, and we are called to action.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_EFSd65B_mq8",
    "outputId": "53c8337a-ace7-4f4c-f903-ebad546f57bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences similar to: \"it's more important than ever that we ground ourselves in the fundamental values that define us as a company.\"\n",
      "\n",
      "0, \"Dear Colleagues, During these extraordinary times, when many parts of our lives have changed, it's more important than ever that we ground ourselves in the fundamental values that define us as a company.\", Exelon.txt\n",
      "1, \"In doing so, we have aligned ourselves with the values that you, our clients, live on a day-to-day basis through your inspiring work – values that are grounded in the dignity and worth of every human being.\", TIAA.txt\n",
      "2, \"But, more than that, we reflect our core values to the world, and we advocate to make the places we live and work more inclusive.\", Dow Chemical.txt\n",
      "3, \"With that in mind, now and each day, we remain guided by Our Purpose and Our Values of Integrity and Honesty, Safety and Respect, Diversity and Inclusion.\", Kroger.txt\n",
      "4, \"One of the key ways we can continue to improve as a company and as individuals is to listen to each other’s perspectives with respect, patience and humility.\", Costco.txt\n",
      "5, \"Our greatest strength is our culture - ultimately, that is a system of values, expectations, and accountability for all of us.\", HCA.txt\n",
      "6, \"Over our company’s history, we have built an environment where we take care of each other, build strong relationships and value respect for all people.\", Home Depot.txt\n",
      "7, \"We are all in this together, and we can only achieve our highest potential if we all work to ensure that we have a culture where everyone feels safe, respected and valued.\", American Express.txt\n",
      "8, \"Importantly, our ability to excel as a globally interconnected work force must be buttressed by a collective sense of purpose and our shared values as a community.\", Goldman Sachs.txt\n",
      "9, \"These values are core to who we are and how we operate.\", Fedex.txt\n",
      "10, \"But we need to be honest about the disparities we know exist in our society, and diligent in continually finding ways to ensure that the values we espouse come to life in our workplace.\", Fannie Mae.txt\n",
      "11, \"That’s why we’re spending time listening to employees and seeking their input on meaningful actions we can take, both internal and external.\", Coca Cola.txt\n",
      "12, \"In order to be successful as a business in empowering everyone on the planet, we need to reflect the world we serve.\", Microsoft.txt\n",
      "13, \"Now, more than ever, is the time for us to listen with open hearts and to lead with empathy — toward each other, toward our customers and toward our communities.\", Publix.txt\n",
      "14, \"Beyond our everyday individual behaviors, we will also act collectively as a company.\", Walmart.txt\n",
      "15, \"While outside our walls, we are also actively working to unify business leaders to use our collective voices to drive change in our communities and workplaces.\", MassMutual.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"Recent racial discrimination incidents in Minnesota, New York, Kentucky and Georgia have drawn widespread national attention\"\n",
      "\n",
      "0, \"Recent racial discrimination incidents in Minnesota, New York, Kentucky and Georgia have drawn widespread national attention and, while not within our company, remind us, once again, that our focus on our values of respect, diversity and inclusion cannot waver.\", Exelon.txt\n",
      "1, \"The murders of George Floyd in Minneapolis, Breonna Taylor in Kentucky, and Ahmaud Arbery in Georgia are the most recent names added to a lengthy list of horrors faced by black people over the past several hundred years.\", Berkshire Hathaway.txt\n",
      "2, \"From the devastating and disproportionate impacts of COVID-19 to the devastating impacts of police brutality, the long-standing racial injustice in America that began 400 years ago is impossible to ignore.\", Dell.txt\n",
      "3, \"This is why I have signed a letter in support of a resolution before the Columbus City Council which would declare racism to be a Public Health Crisis.\", Nationwide.txt\n",
      "4, \"The pandemic coupled with these recent injustices have pushed the issues of racial disparity into the open.\", Disney.txt\n",
      "5, \"In the United States, the company has supported the passage of hate crimes legislation in Georgia, and has committed to urging the governors and legislatures of states without similar legislation – including Arkansas, South Carolina and Wyoming – to prioritize passing a bill.\", UPS.txt\n",
      "6, \"Racism continues to be at the root of so much pain and ugliness in our society – from the streets of Minneapolis to the disparities inflicted by COVID-19.\", CitiBank.txt\n",
      "7, \"LOUISVILLE, Ky.--(BUSINESS WIRE)--Today, Humana (NYSE: HUM) announced actions to support its hometown of Louisville in its efforts to address racial inequity and unite toward a stronger community.\", Humana.txt\n",
      "8, \"Recent events in America are a sobering reminder of our country’s long and troubled history of racial inequality and injustice.\", Capital One.txt\n",
      "9, \"Racial injustice affects cities and towns across our nation.\", AT&T.txt\n",
      "10, \"The racist events that have taken place over the last few weeks have shaken us deeply and bring to the forefront the ongoing issues of racisms in the U.S.\", Pfizer.txt\n",
      "11, \"It is ripping at the fabric of our communities, revealing the open wounds of race relations in this country.\", New York Life Insurance.txt\n",
      "12, \"Laurie Nordquist, Upper Midwest lead region president, has joined with leaders from other Minneapolis companies in making a joint statement to express their outrage about Mr. Floyd’s death and their commitment to investing in substantive change to address racial inequities and social justice.\", Wells Fargo.txt\n",
      "13, \"• NAACP Legal Defense and Educational Fund, a leading legal organization fighting for racial justice.\", Verizon.txt\n",
      "14, \"“Systemic racism and the events that have unfolded across America over the past few weeks serve as an urgent reminder of the continued change needed in our society.\", nike.txt\n",
      "15, \"We also recognize that while the events in Minneapolis shock the consciences of all, they touch our African American employees in particular and painful ways.\", Fannie Mae.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"our focus on our values of respect, diversity and inclusion cannot waver. \"\n",
      "\n",
      "0, \"Diversity and respect for all people are core to who we are as an Orange-Blooded family.\", Home Depot.txt\n",
      "1, \"We remain committed to ensuring that we have a welcoming and inclusive environment where everyone’s voice matters and where people of all backgrounds, cultures and viewpoints can thrive.\", American Express.txt\n",
      "2, \"We also realize that now more than ever is the time for us all to further strengthen our commitment to diversity and inclusion everywhere.\", Disney.txt\n",
      "3, \"We remain committed to promoting diversity and inclusion, respect and integrity within our own company, and in the communities where we live and work, and we understand the urgency to act now to fight systemic racism and ensure equality for all.\", ADM.txt\n",
      "4, \"But deep in our hearts, all of us know we can do even more to make AbbVie a leader in equality, diversity and inclusion.\", AbbVie.txt\n",
      "5, \"These tragedies have reaffirmed our commitment to live by our Sysco Values and cultivate a company culture that makes diversity, inclusiveness, equality and belonging top priorities.\", Sysco.txt\n",
      "6, \"We are committed to not only being a voice, but also doing the right things to fully embrace equality, diversity and inclusion and loudly reject racism and all forms of bias.\", AbbVie.txt\n",
      "7, \"As a company that is deeply committed to diversity, inclusion and human rights, we will strengthen our resolve in advocating for change and in doing our part so that we build a society that protects all people and values all voices.\", MetLife.txt\n",
      "8, \"It stresses the importance of fostering diversity and inclusion, dignity, and respect among our employees and supporting and respecting the communities in which we work.\", Wells Fargo.txt\n",
      "9, \"Diversity and inclusion are foundational to The Chevron Way and it is up to all of us to be present, be allies and be actionable in the ugly face of racism, discrimination and injustice.\", chevron.txt\n",
      "10, \"With that in mind, now and each day, we remain guided by Our Purpose and Our Values of Integrity and Honesty, Safety and Respect, Diversity and Inclusion.\", Kroger.txt\n",
      "11, \"We believe our team members learn from, understand and ultimately grow from our inherent racial, cultural, religious and gender differences.\", Tyson.txt\n",
      "12, \"We seek and embrace diversity.\", Capital One.txt\n",
      "13, \"We must stand with all who are committed to change that will bring us closer to realizing an end to discrimination and hatred.\", Home Depot.txt\n",
      "14, \"We are committed to fostering a culture of respect.\", GE.txt\n",
      "15, \"Diversity, equity and inclusion are fundamental to our core values and to an environment where all people can bring their authentic selves to work and feel safe, welcomed, valued and respected.\", Progressive.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"Supporting, encouraging and engaging everyone in our company – no matter their gender, color of their skin, sexual orientation, disability, religion, point of view or other unique qualities – are actions we must take every day. \"\n",
      "\n",
      "0, \"Supporting, encouraging and engaging everyone in our company – no matter their gender, color of their skin, sexual orientation, disability, religion, point of view or other unique qualities – are actions we must take every day.\", Exelon.txt\n",
      "1, \"The values we embrace in pursuit of this mission are built upon the belief that every individual has unique and intrinsic value, regardless of race, gender, religion, sexual orientation, or whatever makes us different.\", HCA.txt\n",
      "2, \"Each person who walks through our doors — no matter their race, religion, age, gender identity, or any other type of background — will be treated with Courtesy, Dignity, and Respect.\", Albertsons.txt\n",
      "3, \"We believe our team members learn from, understand and ultimately grow from our inherent racial, cultural, religious and gender differences.\", Tyson.txt\n",
      "4, \"\"We, as a global health service company, firmly and unequivocally denounce racism and discrimination in all forms and are committed to confronting these issues with intensity, empathy and accountability.\"\", Cigna.txt\n",
      "5, \"We strive to have a diverse employee population and recognize that only by interacting with, and listening to people of all races, backgrounds, ethnicities, sexual orientations and abilities can we hope to truly understand and appreciate one another.\", Comcast.txt\n",
      "6, \"We do many things so well, however we have not found a meaningful way to engage in the courageous conversations around race, gender and orientation bias.\", USAA.txt\n",
      "7, \"And it is one that requires all of us, in our professional and personal lives, to define who we are through words and deeds that reject racism and bias and repel discrimination and hatred.\", New York Life Insurance.txt\n",
      "8, \"Each of us is a product of our life experiences and those are shaped by our gender, ethnic background and orientation, including the color of our skin.\", USAA.txt\n",
      "9, \"We remain committed to promoting diversity and inclusion, respect and integrity within our own company, and in the communities where we live and work, and we understand the urgency to act now to fight systemic racism and ensure equality for all.\", ADM.txt\n",
      "10, \"Diversity and inclusion are foundational to The Chevron Way and it is up to all of us to be present, be allies and be actionable in the ugly face of racism, discrimination and injustice.\", chevron.txt\n",
      "11, \"“Caring for each other and respecting differences is who we are as a company, and we do not tolerate racism or discrimination of any kind.\", Humana.txt\n",
      "12, \"We are committed to not only being a voice, but also doing the right things to fully embrace equality, diversity and inclusion and loudly reject racism and all forms of bias.\", AbbVie.txt\n",
      "13, \"- Providing a 2:1 match for employees who wish to support organizations working to help address racial equality and social justice issues.\", AbbVie.txt\n",
      "14, \"We’ll continue to educate and show our leaders and associates how to be stronger allies – to be more empathetic, supportive and aware of our own unconscious bias.\", Kroger.txt\n",
      "15, \"We stand against hate-filled behavior and language, and remain dedicated to our global commitment to treat everyone with empathy, dignity and respect.\", Liberty Mutual Insurance.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"While social distancing separates us, this is not a time to be passive, but a time to reach out to colleagues, engage in a dialogue, make sure they're okay and their voices are heard. To let them know they are valued and important.\"\n",
      "\n",
      "0, \"While social distancing separates us, this is not a time to be passive, but a time to reach out to colleagues, engage in a dialogue, make sure they're okay and their voices are heard.\", Exelon.txt\n",
      "1, \"Now, more than ever, is the time for us to listen with open hearts and to lead with empathy — toward each other, toward our customers and toward our communities.\", Publix.txt\n",
      "2, \"To guard against that, we must continue to be aware of what is happening, speak out against injustices and be willing to talk candidly in an environment of honest dialogue.\", Goldman Sachs.txt\n",
      "3, \"We’re creating more opportunities for our associates to openly share their thoughts and feelings about their experiences with discrimination – and for our company and leaders to more deeply and deliberately listen.\", Kroger.txt\n",
      "4, \"Listening with compassion and taking action when it is needed are critical to ensuring that racism and hatred have no place at our company.\", Albertsons.txt\n",
      "5, \"In the coming days, I encourage each of us to step outside of our comfort zones, seek to understand, engage in productive conversations and hold ourselves accountable for being part of the solution.\", Nationwide.txt\n",
      "6, \"For me, it starts with seeing the situation for what it is, acknowledging these experiences for what they are and, quite simply, apologizing for not doing enough.\", Best Buy.txt\n",
      "7, \"I ask you to reflect on your individual thoughts and actions and ensure they are consistent with Our Values.\", Caterpillar.txt\n",
      "8, \"My advice for each of us is to actively listen to each other, forgive well-intentioned questions or comments as we have what can be uncomfortable conversations, create a safe space for learning and be purposeful about what you read and listen to.\", Walmart.txt\n",
      "9, \"We should demonstrate empathy and kindness in all our actions and be willing to address these topics in and outside of the workplace.\", Fedex.txt\n",
      "10, \"We’ll continue to educate and show our leaders and associates how to be stronger allies – to be more empathetic, supportive and aware of our own unconscious bias.\", Kroger.txt\n",
      "11, \"I believe that listening to diverse perspectives and summoning the courage to start crucial conversations is the first step in fostering inclusivity and creating environments where each of us feels like we belong.\", USAA.txt\n",
      "12, \"The last few days, in particular, have been a painful reminder that there must be a deeper and more robust dialogue about our values, and we must live those values, as well as continue our efforts to foster a diverse and respectful work environment.\", AIG.txt\n",
      "13, \"We know that the first step toward change is to speak up, so I want to be very clear: Black Lives Matter, to our company and to me.\", Pepsico.txt\n",
      "14, \"Each of us, starting with me, must look at where we are as individuals, confront our fixed mindset and act.\", Microsoft.txt\n",
      "15, \"Each of us can make a difference simply by asking how others are doing and spending time listening to their experiences, fears, and concerns, so we can learn more about what we can do as allies to take meaningful action and offer our support.\", MassMutual.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"There is no room in our company for hate, intolerance, discrimination or harassment of any kind – either obvious or covert – toward our colleagues or customers. \"\n",
      "\n",
      "0, \"There is no room in our company for hate, intolerance, discrimination or harassment of any kind – either obvious or covert – toward our colleagues or customers.\", Exelon.txt\n",
      "1, \"We remain committed to taking care of our employees, building a diverse workforce, maintaining work environments that are free from discrimination and harassment, and treating each other in a fair, honest, respectful and inclusive way.\", Costco.txt\n",
      "2, \"Every member of my team has committed personally to confronting racism and building more inclusive opportunities — both inside our company and in our communities.\", Boeing.txt\n",
      "3, \"If anyone experiences, or witnesses, any behavior that is not in line with our racial discrimination policy, it is our expectation and requirement that you report it immediately to your supervisor, Human Resources, Legal, or the Access Helpline.\", Honeywell.txt\n",
      "4, \"\"We, as a global health service company, firmly and unequivocally denounce racism and discrimination in all forms and are committed to confronting these issues with intensity, empathy and accountability.\"\", Cigna.txt\n",
      "5, \"We’re creating more opportunities for our associates to openly share their thoughts and feelings about their experiences with discrimination – and for our company and leaders to more deeply and deliberately listen.\", Kroger.txt\n",
      "6, \"Remember, we will never tolerate retaliation against those who step forward in good faith to report problems or concerns related to our Harassment Policy or Code of Business Conduct.\", Honeywell.txt\n",
      "7, \"But it is clear that promoting a diverse and inclusive work environment is not enough.\", Tyson.txt\n",
      "8, \"Any incidents of conscious or unconscious bias toward our customers and team members is unacceptable and will be addressed appropriately.\", American Airlines.txt\n",
      "9, \"We’ve delivered implicit bias training for more than 100,000 of our team members and created a specialized customer relations team to listen to, resolve and learn from any customer complaints of discrimination.\", American Airlines.txt\n",
      "10, \"• Enhancing our policies: We will continue to directly address acts of bias and racism whether in social media or our workplace.\", American Airlines.txt\n",
      "11, \"And we are committed to act: We have and will continue to build a diverse employee and leadership base to reflect the consumers we serve, and foster an inclusive, respectful, welcoming and affirming culture.\", P&G.txt\n",
      "12, \"Of course, these issues go far beyond the confines of our company, affecting our families and friends, as well as our colleagues.\", American Express.txt\n",
      "13, \"We strive to make GDIT a place where every employee feels valued and respected; one where employees see themselves and feel heard.\", General Dynamics.txt\n",
      "14, \"We know our words and actions aren’t enough to bring about broader change, so we are working to help enact change at a higher level through my involvement with the Business Roundtable and as a member of the CEO Action for Diversity & Inclusion.\", Progressive.txt\n",
      "15, \"We also provide an independent and confidential compliance hotline, allowing all our employees to freely and confidentially bring up concerns enabling ADM to take appropriate measures to ensure equal opportunities for all.\", ADM.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"We cannot tolerate it and none of us can stand by quietly if we observe it.\"\n",
      "\n",
      "0, \"We cannot tolerate it and none of us can stand by quietly if we observe it.\", Exelon.txt\n",
      "1, \"And we can control how we treat each other.\", American Express.txt\n",
      "2, \"While we cannot control what happens beyond our walls, we can step up, step forward and help create the world in which we want to live.\", P&G.txt\n",
      "3, \"It is all our responsibilities to embrace that fact in what we say and what we do.\", Walmart.txt\n",
      "4, \"As I’ve said before, we must focus on what we can control.\", American Express.txt\n",
      "5, \"We must take this moment to embrace the fundamental values that unite us.\", Raytheon.txt\n",
      "6, \"We can control the words we use, the viewpoints we embrace and the actions we take.\", American Express.txt\n",
      "7, \"To achieve this progress, each of us must live up to our responsibility to work towards true peace.\", AmerisourceBergen.txt\n",
      "8, \"We can lead by example and lean into our inclusive culture.\", Dell.txt\n",
      "9, \"To create change, we have to reexamine our own views and actions in light of a pain that is deeply felt but too often ignored.\", Apple.txt\n",
      "10, \"Issues of human dignity will not abide standing on the sidelines.\", Apple.txt\n",
      "11, \"We can start by living more deeply into our values.\", Intel.txt\n",
      "12, \"We must push ourselves to influence change and create compassion.\", State Farm.txt\n",
      "13, \"We cannot episodically wake up when a new tragedy occurs.\", Microsoft.txt\n",
      "14, \"These are our core beliefs – the essence of who we are – and they do not change, no matter the circumstances.\", Kroger.txt\n",
      "15, \"We have a responsibility to enable change in our communities.\", Northrop Grumman.txt\n",
      "\n",
      "-----\n",
      "sentences similar to: \"These events impact us, our customers and the communities we serve, and we are called to action.\"\n",
      "\n",
      "0, \"These events impact us, our customers and the communities we serve, and we are called to action.\", Exelon.txt\n",
      "1, \"We will continue our focus on being more representative of our consumers while doing our part in the communities we serve.”\", nike.txt\n",
      "2, \"And we are committed to act: We have and will continue to build a diverse employee and leadership base to reflect the consumers we serve, and foster an inclusive, respectful, welcoming and affirming culture.\", P&G.txt\n",
      "3, \"Thank you for all you are doing to support our customers, our communities, and each other.\", Wells Fargo.txt\n",
      "4, \"Beyond our everyday individual behaviors, we will also act collectively as a company.\", Walmart.txt\n",
      "5, \"Further, we are observing Juneteenth as an annual company holiday to provide Allstaters the opportunity to reflect on this monumental event and engage in their communities.\", Allstate.txt\n",
      "6, \"- In light of my call to action and recent events, this Friday, June 19, AbbVie will observe Juneteenth to take the time to reflect on the changes that have to occur in our Company, our communities and society as a whole.\", AbbVie.txt\n",
      "7, \"We act for one another, our customers, our dealers, our communities, and the world around us.\", John Deere.txt\n",
      "8, \"We remain steadfast in our commitment to fairness and equity for our employees, members and communities.\", Costco.txt\n",
      "9, \"We’re openly listening to our associates and community partners, and we’re engaging advocacy groups to further understand what more we can do.\", Kroger.txt\n",
      "10, \"The actions listed below are not exhaustive but reflect some of the many steps in our efforts to reaffirm and reinforce our core values as well as support our country and our team members as we work to drive real, lasting change for our society.\", Tyson.txt\n",
      "11, \"Coca-Cola is committed to making a difference in our communities and within our company by mobilizing our history of advancing civil rights and by rallying the strength of our employees, families and friends.\", Coca Cola.txt\n",
      "12, \"Now, more than ever, is the time for us to listen with open hearts and to lead with empathy — toward each other, toward our customers and toward our communities.\", Publix.txt\n",
      "13, \"Our colleagues, customers and communities demand more from us.\", Sysco.txt\n",
      "14, \"Our response to COVID-19 is an example of how when we come together, united against a common enemy, we are unstoppable in helping each other, our clients and other stakeholders.\", AIG.txt\n",
      "15, \"Over the past year, we have been thinking a lot about the purpose of our organization and the work we do with our customers and partners.\", Cisco.txt\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for sample_query in query_sentences: \n",
    "  num_results = 16  #@param {type:\"slider\", min:0, max:50, step:1}\n",
    "\n",
    "  query_embedding = session.run(embedded_text, feed_dict={text_input: [sample_query]})[0]\n",
    "\n",
    "  search_results = vector_index_chunk.get_nns_by_vector(query_embedding, n=num_results)\n",
    "\n",
    "  print('sentences similar to: \"{}\"\\n'.format(sample_query))\n",
    "  # search_results\n",
    "\n",
    "  for idx, result_idx in enumerate(search_results):\n",
    "    page_num = docs[result_idx]\n",
    "    text = doc_texts.iloc[result_idx][\"text\"]\n",
    "    print(f\"{idx }, \\\"{text}\\\", {page_num}\")\n",
    "\n",
    "  print('\\n-----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6YvctORJWgS"
   },
   "source": [
    "## Wait, how did that work?\n",
    "\n",
    "### Nearest neighbors -- it's what it sounds like.\n",
    "\n",
    "When is a sentence \"similar\" to another?\n",
    "\n",
    "Remember those 512-dimensional vectors? We're treating two sentences as similar if their vectors are close together. Our search results are \"nearest neighbors,\" which is what it sounds like.\n",
    "\n",
    "Imagine the vectors were just three dimensions and we had four sentences, encoded as:\n",
    "\n",
    "1. [1, 2, 1]\n",
    "2. [100, 600, -12]\n",
    "3. [5, 7, 3]\n",
    "4. [-50, 1, -5798]\n",
    "\n",
    "Which sentence is probably the most similar to sentence #1?\n",
    "\n",
    "\"Annoy\" is a library that makes this easier to calculate quickly for hundreds of thousands of sentences. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "311mS63qpp84"
   },
   "source": [
    "**Copyright 2019 The TensorFlow Hub Authors and Quartz.**\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "JMyTNwSJGGWg"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Hub Authors and Quartz All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Mayoral USE searcher for NICAR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
